import pandas as pd
import numpy as np
from sklearn.metrics import (
    roc_auc_score,
    precision_recall_curve,
    roc_curve,
    auc
)

def evaluate_model_metrics_weighted(df):
    y_true = df['true']
    y_score = df['score']
    weights = df['weight']

    # ROC AUC (weighted)
    roc_auc = roc_auc_score(y_true, y_score, sample_weight=weights)

    # Precision-Recall AUC (weighted)
    precision, recall, thresholds_pr = precision_recall_curve(y_true, y_score, sample_weight=weights)
    auc_pr = auc(recall, precision)

    # ROC Curve and KS (weighted)
    fpr, tpr, thresholds_roc = roc_curve(y_true, y_score, sample_weight=weights)
    ks_statistic = max(tpr - fpr)

    # Best threshold using Youden's J (tpr - fpr)
    j_scores = tpr - fpr
    best_index = np.argmax(j_scores)
    best_threshold = thresholds_roc[best_index]

    # Detection Rate: weighted TPR at best threshold
    y_pred = (y_score >= best_threshold).astype(int)
    true_positive_weight = weights[(y_pred == 1) & (y_true == 1)].sum()
    total_positive_weight = weights[y_true == 1].sum()
    detection_rate = true_positive_weight / total_positive_weight if total_positive_weight > 0 else 0

    # Log-odds (element-wise on score)
    eps = 1e-10  # To avoid division by zero
    odds = (y_score + eps) / (1 - y_score + eps)
    log_odds = np.log(odds)

    # Return results
    return {
        'roc_auc': roc_auc,
        'auc_pr': auc_pr,
        'ks_statistic': ks_statistic,
        'detection_rate': detection_rate,
        'best_threshold': best_threshold,
        'log_odds': log_odds  # This is a Series, can be added to the df if needed
    }

# Example usage:
# df = pd.DataFrame({'true': [0,1,0,1], 'score': [0.2,0.8,0.3,0.9], 'weight': [1,2,1,3]})
# results = evaluate_model_metrics_weighted(df)
# print(results)
