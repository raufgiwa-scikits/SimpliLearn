
Interpretable machine learning remains a central challenge in the application of deep models to scientific and engineering data. The Generalized Additive Model with Structured Interactions Network (GAMI-Net) has emerged as a promising framework that balances transparency and predictive power. However, many scenarios produce functional data—signals, trajectories, or fields—whose information lies in their entire shape rather than isolated scalar measurements. Typical examples are scenarios where a data has short term and long term components frequently found in healthcare, finance, atmospheric data.

We introduce the Functional GAMI-Net (F-GAMI-Net-2), an interpretable deep-learning architecture that extends additive modeling of GAM-2 to function-valued predictors. Each main effect is modeled as a functional operator—implemented through basis decompositions, convolutional encoders, neural operator layers—while preserving GAMI-Net’s additive and hierarchical structure. Orthogonality, centering, and heredity constraints guarantee well-defined, disentangled contributions among scalar and functional effects. 

Pair wise effects allows for higher order accuracy which are not captured by main effects.

When applied to synthetic and real-world datasets—including temporal, spatial, and physical signals—F-GAMI-Net captures non-linear dependencies while retaining transparent effect visualizations over time and domain space. This framework establishes a path toward physics-informed, interpretable learning for complex systems where both predictive accuracy and scientific insight are essential.
